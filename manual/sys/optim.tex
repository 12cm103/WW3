%\input{sys/fig_struc1}

\vsssub
\subsubsection{~Multiple grids} \label{sec:mgrids}
\vsssub

So far, only a single wave model grid has been considered.  To make it
possible to run several model grids in a single program, a data structure
needs to be devised in which all different model grids and internal work
arrays for all models are retained simultaneously, with a simple mechanism to
choose the actual wave model grid to work on. In order to achieve this, some
FORTRAN 90 features \citep[e.g.,][]{bk:MR99} are used in the following way:


\begin{list}{}{\rightmargin 8mm \leftmargin 10mm \labelsep 2mm}

\item [1)] Define one or more data structures in the model code that contain
           the model setup and relevant work arrays, using a {\F type}
           declaration.

\item [2)] Construct arrays of these data structures, with each element of the
           array defining a separate model grid.

\item [3)] Redefine the basic parameters describing the model such as the
           number of grid points {\F nx} and {\F ny} as pointers, and point
           these to the proper element of the proper data structures to
           generate instantaneous aliases.

\end{list}

\noindent
In this way it is possible to define a multi-model data structure, while
keeping the layout of all original variables describing the model unchanged
inside the model subroutines.  Such a structure and its usage are illustrated
in Figs.~\ref{fig:struc_1} and \ref{fig:struc_2} with an example from the
actual source code. Note that the pointer arrays like {\F zb} inside the
structures are assigned memory as \command{\F allocate grids(imod)\%zb(nsea)}
After this statement, the alias pointer {\F zb} again needs to be pointed to
the proper element of the structure for this alias to properly point to the
newly allocated space. For this reason, the subroutine {\F w3dimx}, which
allocates the arrays in this structure, includes at the end a call to the
subroutine {\F w3setx}, which in turn sets all pointer aliases for the
selected grid. The same is true for other subroutines setting array sizes in
other structures.

\input{sys/fig_struc2}

\vssub
\subsection{~Optimization} \label{sec:optim}
\vssub

The source code of \ws\ is written in ANSI standard FORTRAN 90, and has been
compiled and run on a variety of platforms ranging from PC's to
supercomputers.

Optimization for vector computers has been performed by structuring the code
in long vector loops where possible. Optimization was originally performed for
the Cray YMP and C90. Note that some compiler directives for vectorization
have been used. Note also that the vector optimization has not been updated
since about 1997, and therefore needs to be revisited if the model is
implemented on a vector machine. Vectorization directives are activated by the
corresponding preprocessor switch ({\F c90}).

Parallelization for shared memory machines using threading has been
implemented using standard OpenMP directives. Such parallelization takes place
mainly in the loop calling the source term routine {\F w3srce} and the
different propagation routines. OpenMP directives are activated by the
corresponding preprocessor switches ({\F omp}{\it n}).

Parallelization for distributed memory machines is discussed in some detail in
section~\ref{sec:distr}.

Note that an important part of the optimization is the use of interpolation
tables for the solution of the dispersion relation and for the calculation of
the wind-wave interaction parameter).
